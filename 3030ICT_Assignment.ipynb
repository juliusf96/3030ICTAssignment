{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c22d4312",
      "metadata": {
        "id": "c22d4312"
      },
      "source": [
        "<h1>3030ICT Assignment</h1>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "SJERDCRqESF2",
        "outputId": "e5c7f3a7-36e4-4a71-d6e1-e34df09e29bb"
      },
      "id": "SJERDCRqESF2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-53874a984627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 76800"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ffb7f51",
      "metadata": {
        "id": "4ffb7f51"
      },
      "source": [
        "<h2>Part 1 – Data Preparation and Preprocessing. [15 points]</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7074a99a",
      "metadata": {
        "id": "7074a99a"
      },
      "source": [
        "<h3>1. Describe the dataset. (8 points)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ea0e04",
      "metadata": {
        "id": "e5ea0e04"
      },
      "source": [
        "<ul>\n",
        "    <li>Describe the dataset (e.g.: type of column, value range). (1 point) </li>\n",
        "    <li>How many records are there in the dataset? (1 point) </li>\n",
        "    <li>Which period does it cover? How many different dates have job postings? (1 point) </li>\n",
        "    <li>How many locations does the dataset have? Which location has the most job postings? (1 point) </li>\n",
        "    <li>How many job sectors(job classifications) are there in the dataset? List the name of each sector and its’ total of job postings. (1 point) </li>\n",
        "    <li>Choose your favorite job sector (e.g. Information & Communication Technology), how many sub-sectors are there in that sector? List the name of each sub-sector and its’ job posting number. (1 point) </li>\n",
        "    <li>List the salary ranges and their total of job postings. (1 point) </li>\n",
        "    <li>List the job types. In each job type, what are the lowest salary and highest salary? (1 point)</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3fc27ce",
      "metadata": {
        "id": "e3fc27ce"
      },
      "outputs": [],
      "source": [
        "#Ben"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07f4e959",
      "metadata": {
        "id": "07f4e959"
      },
      "source": [
        "<h3>2. Normalize and clean data. (7 points)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e8f8da",
      "metadata": {
        "id": "d1e8f8da"
      },
      "source": [
        "<ul>\n",
        "    <li>The salaries are kept in the dataset as “HighestSalary” and “LowestSalary”. You should calculate the “AverageSalary” for each job. (1 point)</li>\n",
        "    <li>The raw dataset values of the \"Id\" column had inconsistencies in their representation. The Id values should have 8 number long integers only. Write code to remove unnecessary characters. (1 point)</li>\n",
        "    <li>The \"Date\" column is represented in a format that contained both date and time information. However, the time is not correct and should be removed. (1 point)</li>\n",
        "    <li>Change type of “Id” column to numeric and change type of “Date” column to DateTime. (1 point) </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89146a02",
      "metadata": {
        "id": "89146a02"
      },
      "outputs": [],
      "source": [
        "#Julius"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.\n",
        "df['AverageSalary'] = (df['HighestSalary'] + df['LowestSalary']) / 2\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "pWsD7pYmMOhk"
      },
      "id": "pWsD7pYmMOhk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.\n",
        "#regex snacks\n",
        "df['Id'].describe()\n",
        "df['Id'].info()\n",
        "\n",
        "df['Id'].head(5)"
      ],
      "metadata": {
        "id": "_oWV1jepE_Ka"
      },
      "id": "_oWV1jepE_Ka",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regex snacks\n",
        "df['Date'].describe()\n",
        "df['Date'].info()\n",
        "\n",
        "df['Date'].head(5)"
      ],
      "metadata": {
        "id": "o81VV8hsFdlB"
      },
      "id": "o81VV8hsFdlB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Id'] = pd.to_numeric(df['Id'])\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "MUaiCTLVFeXx"
      },
      "id": "MUaiCTLVFeXx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9016e0fe",
      "metadata": {
        "id": "9016e0fe"
      },
      "source": [
        "<h2>Part 2 – Data Understanding. [5 points] </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ac2cde",
      "metadata": {
        "id": "b1ac2cde"
      },
      "source": [
        "<ul>\n",
        "    <li>Get the salary ranges using “AverageSalary”, the total jobs of each range and display them in the bar chart. (1 point)</li>\n",
        "    <li>Display the list of job types and the number of jobs of each type using pie chart. (1 point)</li>\n",
        "    <li>Display the list of job sectors and the number of jobs of each type using horizontal bar chart. (1 point)</li>\n",
        "    <li>Choose your favorite location. Visualize the market share of that location in pie chart. (1 point)</li>\n",
        "    <li>Can you find the salary distribution for the top 30 cities for the number of job postings? Visualize them in the boxplot chart. (1 point)</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49c6185",
      "metadata": {
        "id": "b49c6185"
      },
      "outputs": [],
      "source": [
        "#1-3 -> Julius\n",
        "#4-5 -> Ben"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salaryDistribution = df['AverageSalary'].value_counts()\n",
        "sns.barplot(x=\"AverageSalary\", y=\"Count\", data=salaryDistribution) # are they in the correct order?"
      ],
      "metadata": {
        "id": "49mSTRSqINSz"
      },
      "id": "49mSTRSqINSz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueTypes = df['Type'].unique()\n",
        "print(uniqueTypes)\n",
        "typeDistribution = df['Type'].value_counts()\n",
        "plt.pie(typeDistribution, labels = uniqueTypes, autopct='%.0f%%')"
      ],
      "metadata": {
        "id": "Jz8o6ijuINX4"
      },
      "id": "Jz8o6ijuINX4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueSectors = df['Sector'].unique()\n",
        "print(uniqueSectors)\n",
        "sectorDistribution = df['Sector'].value_counts()\n",
        "sns.barplot(x=\"Sector\", y=\"Count\", data=sectorDistribution)"
      ],
      "metadata": {
        "id": "RgBV22XRINfY"
      },
      "id": "RgBV22XRINfY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "14c01e95",
      "metadata": {
        "id": "14c01e95"
      },
      "source": [
        "<h2>Part 3 – Data Analysis and Visualisation. [6 points]</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2b0454",
      "metadata": {
        "id": "7e2b0454"
      },
      "source": [
        "<h3>1. Analyse by comparison. (2 points)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd85ffff",
      "metadata": {
        "id": "fd85ffff"
      },
      "source": [
        "Choose your two favourite cities/locations. We will explore the difference between them by answering the following questions:\n",
        "<ul>\n",
        "    <li>Which city has more job? How many jobs each type (casual, fulltime, etc.) are there in each city? </li>\n",
        "    <li>In each city, which are top 5 job sectors? How many jobs are there in each sector? </li>\n",
        "    <li>Visualise the top 5 job sectors in pie chart for each city.* </li>\n",
        "    <li>In each city, list the job salary range with the corresponding number of jobs. Which city is more well-paid? </li>\n",
        "    <li>List top 5 companies in each city? Which sectors do they belong to? </li>\n",
        "    <li>Between 2 cities, which do you think it is better for employees. Explain your choice.*</li>\n",
        "<ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e56f09da",
      "metadata": {
        "id": "e56f09da"
      },
      "outputs": [],
      "source": [
        "#1-3 -> Julius\n",
        "#4-6 -> Ben"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b257851",
      "metadata": {
        "id": "4b257851"
      },
      "source": [
        "<h3>2. Analyse by time. (2 points) </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42d94e30",
      "metadata": {
        "id": "42d94e30"
      },
      "source": [
        "In this part, we will analyse the jobs based on the posting date. \n",
        "<ul>\n",
        "    <li>Visualise the number of job posts by month</li>\n",
        "    <li>Visualise the number of job posts by day of week.</li>\n",
        "    <li>Visualise the number of job posts by day of the month.</li>\n",
        "    <li>Visualise trending of the job postings for the big cities.*</li>\n",
        "    <li>Based on the above charts, provide your observation about the number of job posts over time. Give your own conclusion.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa79db9d",
      "metadata": {
        "id": "fa79db9d"
      },
      "outputs": [],
      "source": [
        "#Ben"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea2d9c4",
      "metadata": {
        "id": "2ea2d9c4"
      },
      "source": [
        "<h3>3. Forecasting and skill extractions. (2 points)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93ea6837",
      "metadata": {
        "id": "93ea6837"
      },
      "source": [
        "<ul>\n",
        "    <li>Using moving average for 7 days and 30 days to predict the number of job postings and visualise them in line chart. Which one creates a better prediction? Explain your choice.**</li>\n",
        "    <li>Choose your favourite job sector/sub-sector, then use TF/IDF to extract important keywords. Visualise them in word cloud chart (hint: you can use the online tool https://wordart.com/create or similar websites)**.</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da559fec",
      "metadata": {
        "id": "da559fec"
      },
      "outputs": [],
      "source": [
        "#Julius"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df50e69b",
      "metadata": {
        "id": "df50e69b"
      },
      "source": [
        "<h2>Part 4 – Discussion. [4 points] </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "363a53fd",
      "metadata": {
        "id": "363a53fd"
      },
      "source": [
        "<ul>\n",
        "    <li><strong>Scenario 1:</strong> Tom, a grade 12 student in Brisbane, has good results in all of the subjects in his school. He is finding a major in the University which can guarantee a job in his state (Queensland) with a good income (>=80K) in the future. Based on the current job market dataset, which major and the related subjects do you recommend him? Explain your choice.*** ( Max 750 words) </li>\n",
        "    <li><strong>Scenario 2:</strong> To gain a better reputation, Griffith University wants to attract more students by enhancing the employability of the graduates. As a data analyst, you need to give the recommendation for the management board for the changing of the admission numbers in each major. Which majors should be extended, and which majors should be reduced (Assume that we only need to use job market data, regardless of other factors such as social impact, economic impact, etc. )? Justify your recommendation.*** ( Max 750 words)</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be864797",
      "metadata": {
        "id": "be864797"
      },
      "outputs": [],
      "source": [
        "#1 -> Ben\n",
        "#2 -> Julius"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "3030ICT_Assignment.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}